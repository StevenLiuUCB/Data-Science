{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers={'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:58.0) Gecko/20100101 Firefox/58.0',\n",
    "    'From': 'data-x@gmail.com' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"room\", \"area\", \"price\", \"orient\", \"level\", \"dec\", \"line\", \"linedistance\", \"district\", \\\n",
    "                           \"school\", \"time\", \"elevator\", \"unknown1\", \"unknown2\", \"unknown3\", \"unknown4\", \"web\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapy(webs):\n",
    "\n",
    "    room = []\n",
    "    area = []\n",
    "    price = []\n",
    "    orient = []\n",
    "    level = []\n",
    "    dec = []\n",
    "    line = []\n",
    "    linedistance = []\n",
    "    district = []\n",
    "    school = []\n",
    "    time = []\n",
    "    elevator = []\n",
    "    unknown1 = []\n",
    "    unknown2 = []\n",
    "    unknown3 = []\n",
    "    unknown4 = []\n",
    "    web = []\n",
    "    df1 = pd.DataFrame(columns=[\"room\", \"area\", \"price\", \"orient\", \"level\", \"dec\", \"line\", \"linedistance\", \"district\", \\\n",
    "                           \"school\", \"time\", \"elevator\", \"unknown1\", \"unknown2\", \"unknown3\", \"unknown4\", \"web\"])\n",
    "    try:\n",
    "        source = requests.get(webs, headers=headers).content\n",
    "        soup = BeautifulSoup(source,'html.parser')\n",
    "        #basci info\n",
    "        d = soup.find_all(class_='tt')\n",
    "        room.append(d[0].text)\n",
    "        area.append(d[1].text)\n",
    "        price.append(d[2].text)\n",
    "        orient.append(d[3].text)\n",
    "        level.append(d[4].text)\n",
    "        dec.append(d[5].text)\n",
    "        #other info\n",
    "        d = soup.find_all(class_='rcont')\n",
    "        d1 = re.findall(r'\\((.*)\\)', d[0].text)\n",
    "        try:\n",
    "            d1 = re.findall(r'[0-9]+', d1[0])\n",
    "            line.append(d1[0])\n",
    "            linedistance.append(d1[1])\n",
    "        except:\n",
    "            line.append(0)\n",
    "            linedistance.append(0)\n",
    "        d2 = re.findall(r'\\S+', d[1].text)\n",
    "        district.append(d2[0])\n",
    "        web.append(webs)\n",
    "        try:\n",
    "            sch = soup.find(class_='rcont rcont-school').text\n",
    "            school.append(1)\n",
    "            del d[2]\n",
    "        except:\n",
    "            school.append(0)\n",
    "        while not (d[2].text.startswith('19') or d[2].text.startswith('20')):\n",
    "            del d[2]\n",
    "        time.append(d[2].text)\n",
    "        elevator.append(d[3].text)\n",
    "        unknown1.append(d[4].text)\n",
    "        unknown2.append(d[5].text)\n",
    "        unknown3.append(d[6].text)\n",
    "        unknown4.append(d[7].text)\n",
    "        df1.room = room\n",
    "        df1.area = area\n",
    "        df1.price = price\n",
    "        df1.orient = orient \n",
    "        df1.level = level\n",
    "        df1.dec = dec\n",
    "        df1.line = line\n",
    "        df1.linedistance = linedistance\n",
    "        df1.district = district\n",
    "        df1.school = school\n",
    "        df1.time = time\n",
    "        df1.elevator = elevator\n",
    "        df1.unknown1 = unknown1\n",
    "        df1.unknown2 = unknown2\n",
    "        df1.unknown3 = unknown3\n",
    "        df1.unknown4 = unknown4\n",
    "        df1.web = web\n",
    "        return df1\n",
    "    except:\n",
    "        return pd.DataFrame(columns=[\"room\", \"area\", \"price\", \"orient\", \"level\", \"dec\", \"line\", \"linedistance\", \"district\", \\\n",
    "                           \"school\", \"time\", \"elevator\", \"unknown1\", \"unknown2\", \"unknown3\", \"unknown4\", \"web\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapy(\"http://esf.sh.fang.com/chushou/3_319649421.htm\")\n",
    "#scrapy(\"http://esf.sh.fang.com/chushou/3_319943960.htm\")\n",
    "#scrapy(\"http://esf.sh.fang.com/chushou/3_319935596.htm\")\n",
    "#http://esf.sh.fang.com/\n",
    "def scrapy_page(ii, df):\n",
    "\n",
    "    source = requests.get('http://esf.sh.fang.com/house/i3%d'%ii, headers=headers).content\n",
    "    soup = BeautifulSoup(source,'html.parser')\n",
    "    a = soup.find_all(class_='title')\n",
    "    for num, i in enumerate(a):\n",
    "        s = i.find('a').get('href')\n",
    "        df = df.append(scrapy(\"http://esf.sh.fang.com{}\".format(s)), ignore_index=True)\n",
    "        if num % 10 == 0:\n",
    "            print('done with number ', num+(ii-1)*30)\n",
    "    \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with number  2520\n",
      "done with number  2530\n",
      "done with number  2540\n",
      "done with page 85 , wait for 15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with number  2550\n",
      "done with number  2560\n",
      "done with number  2570\n",
      "done with page 86 , wait for 15s\n",
      "done with number  2580\n",
      "done with number  2590\n",
      "done with number  2600\n",
      "done with page 87 , wait for 15s\n",
      "done with number  2610\n",
      "done with number  2620\n",
      "done with number  2630\n",
      "done with page 88 , wait for 15s\n",
      "done with number  2640\n",
      "done with number  2650\n",
      "done with number  2660\n",
      "done with page 89 , wait for 15s\n",
      "done with number  2670\n",
      "done with number  2680\n",
      "done with number  2690\n",
      "done with page 90 , wait for 15s\n",
      "done with number  2700\n",
      "done with number  2710\n",
      "done with number  2720\n",
      "done with page 91 , wait for 15s\n",
      "done with number  2730\n",
      "done with number  2740\n",
      "done with number  2750\n",
      "done with page 92 , wait for 15s\n",
      "done with number  2760\n",
      "done with number  2770\n",
      "done with number  2780\n",
      "done with page 93 , wait for 15s\n",
      "done with number  2790\n",
      "done with number  2800\n",
      "done with number  2810\n",
      "done with page 94 , wait for 15s\n",
      "done with number  2820\n",
      "done with number  2830\n",
      "done with number  2840\n",
      "done with page 95 , wait for 15s\n",
      "done with number  2850\n",
      "done with number  2860\n",
      "done with number  2870\n",
      "done with page 96 , wait for 15s\n",
      "done with number  2880\n",
      "done with number  2890\n",
      "done with number  2900\n",
      "done with page 97 , wait for 15s\n",
      "done with number  2910\n",
      "done with number  2920\n",
      "done with number  2930\n",
      "done with page 98 , wait for 15s\n",
      "done with number  2940\n",
      "done with number  2950\n",
      "done with number  2960\n",
      "done with page 99 , wait for 15s\n",
      "done with number  2970\n",
      "done with number  2980\n",
      "done with number  2990\n",
      "done with page 100 , wait for 15s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for i in range(85,101):\n",
    "    df = pd.read_csv('data_new.csv', index_col=0)\n",
    "    df = scrapy_page(i, df)\n",
    "    df.to_csv('data_new.csv', header=True)\n",
    "    print('done with page %d , wait for 15s'%i)\n",
    "    time.sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('data_new.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with number  0\n"
     ]
    }
   ],
   "source": [
    "df = scrapy_page(1, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa =pd.read_csv('data_new.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'12344'.startswith(r'[1-9]+')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
